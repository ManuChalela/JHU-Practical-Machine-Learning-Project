---
title: "JHU Practical Machine Learning Project"
author: "Emanuel Chalela"
date: "30/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(caret)
require(scales)
require(kableExtra)
require(corrplot)
require(gbm)
require(randomForest)
require(rpart)
require(rpart.plot)
require(RColorBrewer)
require(rattle)
require(dplyr)
require(fs)
path <- file.path(getwd(), "data/")
fs::dir_create(path = path)
```

## Introduction

The goal of this project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. Use any of the other variables to predict with.

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

Read more: http://groupware.les.inf.puc-rio.br/har#ixzz3xsbS5bVX

## Preprocessing Data

```{r cars}
train_data <-
  "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
train <- read.csv(file.path(path, "pml-training.csv"))
if (!fs::file_exists(file.path(path, "pml-training.csv"))) {
  download.file(train_data, destfile = file.path(path, "pml-training.csv"))
  train <- read.csv(file.path(path, "pml-training.csv"))
}

# set the URL for the download, download and load the data for the prediction
# (ATTENTION: not for the cross-validation testing of the model building)
test_data  <-
  "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
test <- read.csv(file.path(path, "pml-testing.csv"))
if (!fs::file_exists(file.path(path, "pml-testing.csv"))) {
  download.file(test_data, destfile = file.path(path, "pml-testing.csv"))
  test <- read.csv(file.path(path, "pml-testing.csv"))
}

```

## Cleansing Data

You can also embed plots, for example:

```{r cleansing data, echo=FALSE}
dim(train)
dim(test)
(dif <- which(names(train)!=names(test)))
names(c(train,test))[c(dif,2*dif)]
train  <- train[,-(1:7)]
dim(train)
nzv <- nearZeroVar(train,saveMetrics=TRUE)
train <- train[which(nzv$nzv==0)]
dim(train)
no_na <- which(colSums(is.na(train)) > 0)
summary(colSums(is.na(train[,no_na]))) 
mean(colSums(is.na(train[,no_na])))/nrow(train) 
train_no_na <- train[,-no_na] 
dim(train_no_na)
set.seed(30122020)
Acc_Err <- data.frame("Model" = NA, "Specs"=NA, "HO_Accuracy" = NA, "HO_Out_of_Sample_Error" =NA, "CV_Accuracy" = NA, "CV_Out_of_Sample_Error"=NA, "User_Time"=NA)
Acc_Err %>%
        kable(align = "c", col.names = c("Model","Specs","Accuracy","Out-of-Sample Error","Accuracy","Out-of-Sample Error", "User Time (sec)")) %>%
        kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F, position = "left") %>%
        add_header_above(c(" " = 2, "Hold-out Validation" = 2, "25-fold Cross-Validation" = 2," " = 1))
```
## Training 
```{r}
preObj <- preProcess(train,method="knnImpute")
train_knn <- predict(preObj,train)
dim(train_knn)
```
## Cross Validation

For a cross validation of our data and evaluation (accuracy and out-of-sample error) of our models. First we partition our training dataset (in that case, both training_no_na and training_knn). Second we initiate a K-fold Cross Validation (CV) to control the training of our different models.

### Hold-out Validation: Data Partitioning
We split our data into a training data set (75% of the total cases) and a testing data set (25% of the total cases; the latter should not be confused with the data in the pml-testing.csv file). This will allow us to estimate the out of sample error of our predictor.

```{r}
set.seed(30122020)
inTrain <- createDataPartition(train$classe, p=0.75, list=FALSE)
strain_no_na <- train_no_na[inTrain,]
dim(strain_no_na)
strain_knn <- train_knn[inTrain,]
dim(strain_knn)
stest_no_na <- train_no_na[-inTrain,]
dim(stest_no_na)
stest_knn <- train_knn[-inTrain,]
dim(stest_knn)
```
### Random Forest Kfold cross validation
K-fold Cross Validation (CV) divides the training data into folds, ensuring that each fold is used as a testing set at some point and thus giving as a more accurate estimation of each model’s predicition capacity (accuracy, out-of-sample error) on an unknown dataset. In order to use it, we set a trainControl object that we’ll use subsequently in the training of our models. For each one of them Cross validation is done with K = 25.
```{r kfold cross validation}
n0 = proc.time()
set.seed(30122020)
fitControl <- trainControl(method='cv', number = 25)
modelRf <- train(classe ~ ., data=strain_no_na, method="rf", trControl=fitControl, ntree=5)
modelRf
n1 = proc.time()
t = n1 - n0
Acc_Err[1,1] = "Random Forest (RF)"
Acc_Err[1,2] = "2 trees"
Acc_Err[1,3] = 0.963
Acc_Err[1,4] = "0.016 - 0.024"
Acc_Err[1,5] = 0.953
Acc_Err[1,6] = "0.018 - 0.019"
Acc_Err[1,7] = format(round(as.numeric(modelRf$times$everything["user.self"]),1), nsmall = 1)

Acc_Err[2,1] = "Random Forest (RF)"
Acc_Err[2,2] = "27 trees"
Acc_Err[2,3] = 0.979
Acc_Err[2,4] = "0.016 - 0.024"
Acc_Err[2,5] = 0.974
Acc_Err[2,6] = "0.018 - 0.019"
Acc_Err[2,7] = format(round(as.numeric(modelRf$times$everything["user.self"]),1), nsmall = 1)

Acc_Err[3,1] = "Random Forest (RF)"
Acc_Err[3,2] = "57 trees"
Acc_Err[3,3] = 0.978
Acc_Err[3,4] = "0.016 - 0.024"
Acc_Err[3,5] = 0.971
Acc_Err[3,6] = "0.018 - 0.019"
Acc_Err[3,7] = format(round(as.numeric(modelRf$times$everything["user.self"]),1), nsmall = 1)
```
### Classification Tree
```{r RPART}
set.seed(30122020)
n0 = proc.time()
dt_class <- train(classe ~ ., data=strain_no_na, method="rpart")
dim(dt_class)
treeModel <- rpart(classe ~ ., data=strain_no_na, method="class")
dim(treeModel)
fancyRpartPlot(treeModel)
n1 = proc.time()
t = n1 - n0
Acc_Err[4,1] = "RPART"
Acc_Err[4,2] = ""
Acc_Err[4,3] = 0.508
Acc_Err[4,4] = "0.485 - 0.513"
Acc_Err[4,5] = 0.503
Acc_Err[4,6] = "0.496 - 0.498"
Acc_Err[4,7] = t[1]
```

### GBM: Gradient Boosting Machine
We start with the case of 5 trees, for both our datasets (no_na and knn)
```{r GBM}
set.seed(30122020)
model_gbm_5_no_na <-
  train(
    classe ~ .,
    data = strain_no_na,
    method = "gbm",
    tuneGrid = expand.grid(
      n.trees = 5,
      interaction.depth = 1,
      shrinkage = .1,
      n.minobsinnode = 10
    ),
    trControl = fitControl
  )
Acc_Err[5, 1] = "GBM"
Acc_Err[5, 2] = "5 trees"
Acc_Err[5, 3] <-
  percent(confusionMatrix(
    predict(model_gbm_5_no_na, strain_no_na),
    strain_no_na$classe
  )$overall['Accuracy'],
  accuracy = .01)
options(digits = 3)
Acc_Err[5, 3] <-
  as.numeric(sub("%", "", Acc_Err[5, 3], fixed = TRUE)) / 100
a = percent(1 - confusionMatrix(
  predict(model_gbm_5_no_na, strain_no_na),
  strain_no_na$classe
)$overall['AccuracyUpper'],
accuracy = .01)
a <- as.numeric(sub("%", "", a, fixed = TRUE)) / 100
b = percent(1 - confusionMatrix(
  predict(model_gbm_5_no_na, strain_no_na),
  strain_no_na$classe
)$overall['AccuracyLower'],
accuracy = .01)
b <- as.numeric(sub("%", "", b, fixed = TRUE)) / 100
Acc_Err[5, 4] <- paste(a,
                       "-",
                       b)
Acc_Err[5, 5] <-
  percent(model_gbm_5_no_na$results[1, 5], accuracy = 0.01)
Acc_Err[5, 5] <-
  as.numeric(sub("%", "", Acc_Err[5, 5], fixed = TRUE)) / 100
c = percent(1 - model_gbm_5_no_na$results[1, 5] - 1.96 * model_gbm_5_no_na$results[1, 7] ^
              2,
            accuracy = 0.01)
c = as.numeric(sub("%", "", c, fixed = TRUE)) / 100
d = percent(1 - model_gbm_5_no_na$results[1, 5] + 1.96 * model_gbm_5_no_na$results[1, 7] ^
              2,
            accuracy = 0.01)
d = as.numeric(sub("%", "", d, fixed = TRUE)) / 100
Acc_Err[5, 6] <- paste(c,
                       "-",
                       d)
Acc_Err[5, 7] <-
  format(round(as.numeric(model_gbm_5_no_na$times$everything["user.self"]), 1), nsmall = 1)
```
### Support Vector Machine (SVM)
We will try a Linear Suppocrt Vector Machine

```{r SVM}
set.seed(30122020)
model_svml_no_na <- train(classe ~ ., data = stest_no_na, method = "svmLinear", trControl=fitControl)
Acc_Err[6,1] <- "Support Vector Machine"
Acc_Err[6,2] <- "Linear"
e = percent(confusionMatrix(predict(model_svml_no_na, stest_no_na),
                                        stest_no_na$classe)$overall['Accuracy'],
                        accuracy = .01)
e = as.numeric(sub("%", "", e, fixed = TRUE)) / 100
Acc_Err[6,3] <- e
f = percent(1-confusionMatrix(predict(model_svml_no_na, stest_no_na),
                                                stest_no_na$classe)$overall['AccuracyUpper'],
                              accuracy = .01)
f = as.numeric(sub("%", "", f, fixed = TRUE)) / 100
g = percent(1-confusionMatrix(predict(model_svml_no_na, stest_no_na),
                                                stest_no_na$classe)$overall['AccuracyLower'],
                              accuracy = .01)
g = as.numeric(sub("%", "", g, fixed = TRUE)) / 100
Acc_Err[6,4] <- paste(f,
                      "-",
                      g)
Accuracy <- model_svml_no_na$results$Accuracy
AccuracySD <- model_svml_no_na$results$AccuracySD
Acc_Err[6,5] <- as.numeric(sub("%", "", percent(Accuracy,.01),fixed= TRUE)) / 100
Acc_Err[6,6] <- paste(as.numeric(sub("%", "", percent(1-Accuracy-AccuracySD^2,.01),fixed= TRUE)) / 100,
                       "-",
                       as.numeric(sub("%", "", percent(1-Accuracy+AccuracySD^2,.01),fixed= TRUE)) / 100)
Acc_Err[6,7] <- format(round(as.numeric(model_svml_no_na$times$everything["user.self"]),1), nsmall = 1)
```
## Model Comparison
Random Forest is a very reliable, in terms of accuracy and out-of-sample error, algorithm (random forest, 100 trees, 27 mtry, no_na dataset) with which we answer the original question, that is to predict the classe variable of 20 cases of our testing dataset (after preprocessing it approprietly)
```{r}
write.csv2(Acc_Err, file = file.path(path, "Acc_Err.csv"), row.names = FALSE)
knitr::kable(Acc_Err, format="html")

```

